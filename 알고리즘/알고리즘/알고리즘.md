**알고리즘(Algorithm)**이란? 어떤 문제를 해결하기 위해 밟아 나가는 연속적인 단계를 말한다.  
예를 들어, 책상 정리를 들 수 있다. 우선 책상 위 모든 물건을 한 쪽으로 치우고, 정리할 항목별로 분류한다. 분류한 뒤 물건을 각각의 자리에 넣고, 필요 없는 물건은 버리거나 보관 상자에 넣는다. 마지막으로 책상을 깨끗이 닦으며 정리한다.

개발자는 보통 알고리즘을 작성, 어떤 자료구조를 그 알고리즘에 적용할지 고미하면서 대부분의 시간을 보낸다 그렇기 때문에 개발자에게 어떤 알고리즘이 더 좋을지를 판단하는 것은 매우 중요한 능력이다.  
어떤 알고리즘을 선택해야 하는지 판단할 수 없다면 효율적인 개발자가 될 수 없다.

알고리즘은 컴퓨터 과학의 기본 개념, 공식적을 정의되지는 않았다.  
알고리즘에는 여러 가지 정의가 있다, 그 중 가장 잘 알려진 것은 도널드 커누스(Donald Knuth)의 정의이다. 커누스는 알고리즘을 ‘입력을 기반으로 출력을 생성하는 명확하고, 효율적이며 유한한 프로세스라고’ 정의

- **명확함(Definiteness)**  
각 단계가 명료하고 간결하며 모호하지 않다는 뜻이다.
- **효율성(Effectiveness)**  
각 동작이 문제 해결에 기여한다는 뜻이다.
- **유한한(Finteness)**  
알고리즘이 유한한 단계를 거친 후 종료된다는 뜻이다.

**정확성(Correctness)**을 추가하는 경우가 많다.  
알고리즘은 입력이 같으면 항상 같은 결과를 내야 한다, 이 결과가 알고리즘이 해결하는 문제의 정확한 답이 있다.

대부분의 알고리즘이 이 요건을 만족하지만 몇 가지 중요한 예외가 있다.  
e.g. 난수 발생기(Random Number Generator)를 만든다면 누군가 입력을 보고 결과를 짐작할 수 없는 무작위성(Randomness)을 목표로 해야 한다. 또한 데이터 과학의 알고리즘 중에는 정확성을 엄격히 따지지 않는 것도 많다. 추정 자체가 불확실하다고 알려진 알고리즘이라면 근삿값을 찾는 것만으로도 충분하다.

하지만 이와 같은 몇 가지 예외를 제외한다면 알고리즘은 앞에서 말한 요건을 항상 만족해야한다.  
책상 정리하기 알고리즘을 작성하였는데, 때때로 물건이 위치가 헷갈려하거나 중요한 서류를 실수로 버리게 된다면, 이 알고리즘에  만족하는 사람은 없을 것이다.

책상 정리하기 알고리즘을 작성하였는데, 때때로 물건이 어디에 있는지 더 헷갈리거나 중요한 서류를 실수로 버리게 된다면, 이 알고리즘에 만족하는 사람은 없을 것이다.

# 알고리즘 분석

한 가지 문제를 해결할 때 여러 가지 알고리즘을 사용할 수 있을 때가 많다.  
리스트를 정렬하는 방법이 다양한 것처럼 말이다. 여러 가지 알고리즘으로 문제를 풀 수 있따면 최선의 알고리즘은 어떻게 찾아야 할까요? 가장 단순한 것? 가장 빠른 것? 가장 짧은 것? 아니면 다른 기준이 있을까?

실행 시간은 알고리즘을 평가하는 기준 중 하나이다.  
알고리즘의 **실행 시간**은 Python 같은 프로그래밍 언어로 만든 알고리즘을 컴퓨터가 실행하는 데 걸리는 시간을 말한다.  
e.g.  1 ~ 5 숫자를 출력하는 Python 알고리즘

```python
for i in range(1, 6):
	print(i)
```

다음과 같이 Python에 내장된 **time** 모듈을 사용하여 이 알고리즘의 실행 시간을 측정할 수 있다.

```python
import time

start = time.time()
for i in range(1, 6):
	print(i)
end = time.time()
print(end - start)
```

**실행 결과**

1
2
3
4
5
0.002009868621826172

---

프로그램이 실행되면 1에서 5까지의 숫자가 출력되고, 여기에 소요된 시간도 출력된다. 0.002초가 걸렸다,

```python
import time

start = time.time()
for i in range(1, 6):
	print(i)
end = time.time()
print(end - start)
```

**실행 결과**

1
2
3
4
5
0.002660512924194336

---

프로그램을 두 번째로 실행하면 실행 시간이 달라진다.   
또 프로그램을 실행한다면 실행 시간은 또 달라질 것이다. 프로그램을 실행하는 순간 컴퓨터가 사용할 수 있는 CPU의 자원이 매번 다르고, 이 자원이 프로그램의 실행 시간에 영향을 미치므로 알고리즘의 실행 시간도 매번 달라진다.

또한 알고리즘의 실행 시간은 컴퓨터의 성능에 따라도 다르다.  
처리 능력이 떨어지는 컴퓨터에서 실행하면 그만큼 느릴 것이고, 성능이 좋은 컴퓨터에서 실행하면 그만큼 빠를 것이다. 프로그램의 실행 시간은 사용하는 프로그래밍 언어에 따라서도 달라진다.  
e.g. C언어  
C언어의 경우 Python보다 실행속도가 더 빠르기 때문에 같은 프로그램이라도 C언어로 작성하면 실행 시간이 짧아진다

알고리즘을 비교할 때 알고리즘의 실행 시간은 컴퓨터 CPU의 자원이나 프로그램이 언어와 같은 여러 가지 변수의 영향을 받으므로 효과적인 기준이 될 수 없다. 이러한 이유로 컴퓨터 과학자들은 알고리즘에 필요한 단계를 살펴보면서 알고리즘을 비교한다.  
두 개 이상의 알고리즘을 비교해야 한다면 프로그래밍 언어나 컴퓨터의 사양과 같은 변수는 제외하고, 알고리즘에 필요한 단계를 수식으로 비교한다.

예시로, 1 ~5까지 숫자를 셌던 프로그램이다

```python
for i in range(1, 6):
	print(i)
```

프로그램은 다섯 번의 루프를 실행하면서 `i`를 출력하므로 총 다섯 번의 단계를 거친다.  
이 알고리즘에 필요한 단계는 `f(n)`으로 표현할 수 있다.

```python
f(n) = 5
```

프로그램이 복잡해지면 `f(n)`도 바뀐다. 출력되는 숫자의 합을 구한다.

```python
count = 0
for i in range(1, 6):
	print(i)
	count += i
```

알고리즘은 이제 열 한 번의 단계를 거쳐야 완료된다.  `count` 변수에 0을 할당, 1부터 5까지 숫자를 다섯 번 출력. 그때마다 출력된 숫자의 합을 구하므로 1 + 5 + 5 = 11 단계가 된다.

```python
f(n) = 11
```

숫자 6을 변수 n으로 바꾼다면?

```python
count = 0
for i in range(1, n):
	print(i)
	count += i
```

f(n)은 다음과 같이 바뀐다

```python
f(n) = 1 + 2n
```

알고리즘 단계는 n 값에 의해 좌우된다.  
f(n)의 1은 첫 번째 단계인 count = 0에 해당. 그 다음 숫자를 출력하고 합을 구하는 2n만큼의 단계까 필요하다.   
e.g. n이 5라면 f(n) = 1 + 2 * 5  
컴퓨터 과학자는 알고리즘의 단계를 나타내는 f(n)의 변수 n을 **데이터 크기**라고 부른다.  
데이터의 크기가 n인 문제를 푸는 데 필요한 시간이 1 + 2n이라고 할 수 있으며, 수학적으로는 T(n) = 1 + 2n이라고 표기.

알고리즘에 필요한 단계를 항상 정확하게 셀 수 없기 때문에 알고리즘의 단계를 수식으로 표현하는 것이 아주 효과적인 방법이라고 할 수는 없다.   
e.g. 알고리즘에 조건문이 많다고 했을 때.  
그 중 어떤 부분이 실행될지 미리 알 수 없을뿐더러 다행스럽게도 정확하게 알 필요는 없다

중요한 것은 n의 변화에 따른 알고리즘 성능의 변화를 예상하는 것이다.  
데이터 세트가 작을 때는 어던 알고리즘이든 별 문제가 없지만 데이터 세트가 아주 클 때는 비효율적인 알고리즘이 곧 재앙이 될 수 있다. 반대로 가장 비효율적인 알고리즘이라 하더라도 데이터의 크기가 1이라면 전혀 문제가 없지만, 실제로 데이터의 크기가 1인 경우는 거의 없다.  
십만, 백만 또는 그 이상일 가능성이 더 크다.

알고리즘이 정확하게 몇 단계를 거치는지가 아니라, 데이터의 크기가 늘어날 때마다 알고리즘의 단계가 얼마나 늘어나느지를 대략적으로 파악하는 것이 가장 중요하다.  
n이 커지면서 f(n)의 한 부분이 급격하게 커지면 그 외에 다른 부분을 비교하는 것이 무의미하다.

```python
def print_it(n):
	# 루프 1
	for i in range(n):
		print(i)
	
	# 루프 2
	for i in range(n):
		print(i)
		for j in range(n):
			print(j)
			for h in range(n):
				print(h)
```

프로그램의 어떤 부분을 봐야 알고리즘에 몇 단계가 필요한지 판단할 수 있을까?  
루프 1과 루프 2 모두 중요한 변수라고 생각할 수 있다. 어쨌든 `n`이 10,000 정도가 된다면 컴퓨터는 두 루프 모두에서 아주 많은 숫자를 출력할 테니까요.

하지만 알고리즘의 효율성을 따질 때 루프 1은 무시해도 될 수준이다.

```python
	# 루프 1
	for i in range(n):
		print(i)
```

이해하기 위해 n이 커질 때 어떤 일이 일어나는지 살펴봐야 한다.  
이 알고리즘의 단계를 나타내는 수식 T(n).

```python
T(n) = n + n**3
```

`for` 함수가 두 번  중첩된 루프를 `n`번 반복하면,  
이는 n의 제곱인 `n**2`로 나타낸다.

e.g. `n`이 10이라면?  
n이 10이라면 10을 10번 반복해야 하므로 `10**2`가 되는 것이다. 마찬가지로 `for` 함수가 세 번 중첩된 루프는 `n**3`으로 나타낼 수 있따. 만약`T(n)`에서 `n`이 10이라면 루프 1에서는 10단계를 거치고, 루프 2에서는 10의 세제곱인 1,000단계를 거친다.  
`n`이 1,000이라면 루프 1에서는 1,000단계, 루프 2에서는 1,000의 세제곱인 10억 단계를 거치게 된다.

`n`이 커지면 커질수록 알고리즘의 두 번째 루프가 너무 빨리 커지기 때문에 첫번째 루프를 따지는 것이 무의미해진다.   
e.g. 알고리즘이 100,000,000개 데이터 대상으로 작동  
100,000,000개 데이터 대상으로 작동한다면 두 번째 루프의 단계가 너무 크기 때문에 첫 번째 루프가 몇 단계를 거치든 신경 쓰지 않게 될 것이다. 데이터가 100,000,000개라면 두 번째 루프의 단계가 1 뒤에 0이 24개나 있는 숫자가 되므로 이런 상황에서 첫 번째 루프의 단계가 100,000,000번이라는 것은 아무 의미가 없다.

따라서 알고리즘의 효율에서 가장 중요한 부분은 ‘n이 커질 때 알고리즘의 단계가 얼마만큼 증가하는가’이므로, 이것을 잘 나타내는 빅 O 표기법을 사용한다. **빅 O 표기법(Big O notation)**은 n이 커짐에 따라 알고리즘의 시간 또는 공간의 요건이 얼마나 커지는지를 나타내는 구학적 표기법을 말한다.

빅 O 표기법은 T(n)에서 규모 함수를 도출하는데, **규모(Order of Magnitude)**란 차이가 아주 큰 등급 체계에서의 크기 차이를 뜻한다.  
규모 함수에서는 알고리즘의 실행 단계를 나타내는 T(n)에서 수식을 지배하는 부분만 남기고, 나머지는 모두 무시. 즉, T(n)에서 가장 지배적인 부분이 빅 O 표기법에서 도출한 알고리즘의 규모가 되는 것이다.

빅 O 표기법에서 가장 널리 사용되는 규모 함수들을 최선(가장 효율적)에서 최악(가장 비효율적) 순서로 나열된 것이다.

상수시간 → 로그 시간 → 선형 시간 → 선형 로그 시간 → 2차 시간 → 3차 시간 → 지수 시간

각각의 규모 함수는 알고리즘의 시간 복잡도를 나타낸다.  
**시간 복잡도(Time Complexity)**란 n이 커짐에 따라 알고리즘이 실행되고 완료될 때까지 필요한 단계를 말한다.

# 상수 시간

가장 효율적인 규모는 **상수 시간 복잡도(Constant Time Complexity)**  
어떤 알고리즘이 n의 크기에 관계없이 동일한 단계만 필요한 경우 ‘알고리즘이 **상수 시간**으로 실행’합니다. 상수 시간 알고리즘을 빅 O 포기법으로 표기하면 0(1)

e.g. 온라인 서점 운영 매일 첫 번째 방문 고객 무료 책 선물.  
이 고객을 `customers` 리스트에 저장. 알고리즘은 대략 다음과 같은 형태가 된다.

```python
free_books = customers[0]
```

알고리즘T(n)은 다음과 같다.

```python
T(n) = 1
```

고객이 아무리 많아도 이 알고리즘에는 하나의 단계만 필요.  
고객이 1,000명, 10,000명이더라도 한 단계로 끝나고, 초 단위로 하더라도 한 단계면 충분. 고객의 수를 x축, 알고리즘의 단계를 y축으로 하는 상수 시간 복잡도를 그래프로 그리면 

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fb32a252-3b2c-4cfe-89f5-ef1ccbf5e945/e10e8117-6b34-49e2-ae69-06e10f00fbce/image.png)

[https://github.com/hea97/TIL/blob/main/알고리즘/알고리즘 기초/Constant Time graph.py](https://github.com/hea97/TIL/blob/main/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B8%B0%EC%B4%88/Constant%20Time%20graph.py)  
(위 링크는 상수 시간 복잡도알고리즘 그래프 구현을 위한 python 코드이다)

상수 시간 알고리즘은 그래프와 같이 알고리즘이 완료될 때까지 필요한 단계가 일정하다.  
데이터 세트가 아무리 커지더라도 알고리즘의 실행 시간이 변하지 않으므로 가장 효율적인 알고리즘이라고 할 수 있다.

# 로그 시간

**로그 시간 복잡도(Logarithmic Time Complexity)**는 상수 시간에 이어 두 번재로 효율적인 시간 복잡도이다. 데이터의 로그에 비례해 알고리즘의 단계가 늘어날 때, 알고리즘이 로그 시간으로 실행된다고 말한다. 로그 시간 복잡도는 실행을 반복할 때마다 알고리즘의 탐색 범위를 1/2로 줄여 나가는 이진 탐색과 같은 알고리즘에서 볼 수 있다.  
빅 O 표기법에서는 로그 시간 알고리즘을 `0(log n)`으로 표기.

로그 시간 복잡도의 그래프 형태.  
로그 시간 알고리즘은 데이터 세트가 커짐에 따라 알고리즘의 실행에 필요한 단계가 천천히 늘어나는 알고리즘을 말한다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fb32a252-3b2c-4cfe-89f5-ef1ccbf5e945/9f72dab0-8853-4a10-abd4-0d94af7c4797/image.png)

[https://github.com/hea97/TIL/blob/main/알고리즘/알고리즘 기초/Logarithmic Time graph.py](https://github.com/hea97/TIL/blob/main/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B8%B0%EC%B4%88/Logarithmic%20Time%20graph.py)  
(위 링크는 로그 시간 복잡도 알고리즘 그래프 구현을 위한 python 코드이다)

# 선형 시간

로그 시간 복잡도 다음으로 효율적인 것은 **선형 시간 복잡도(Linear time Complexity)**  
선형 시간으로 실행되는 알고리즘은 데이터의 크기가 커지는 만큼 같은 비율로 단계가 늘어나는 알고리즘,   
빅 O 표기법에서는 0(n)으로 표기한다

매일 첫 번재로 방문하는 고객에게 무료로 책을 선물하는 대신, 고객 리스트를 훑어 보다 이름이 B로 시작하는 고객에게 책을 선물한다고 생각했을 때.  
고객 리스트가 알파벳 순으로 정렬되지 않으면 B로 시작하는 이름을 하나씩 탐색하며 찾아야 한다.

```python
free_book = False
customers = ["Benjamin", "Olivia", "Liam", "Choloe", "Mason"]
for customer in customers:
	if customer[0] == 'B':
		print(customer)
```

고객이 다섯이라고 햇을 때 프로그램도 이름을 탐색하는데 다섯 번의 단계를 거쳐야한다. 고객이 많으면 많을 수록 그 만큼의 탐색 단계가 필요하다

따라서 이 프로그램의 시간 복잡도는 각각 `free_book`과 `customers`에 해당하는 단계와 고객 리스트에서 B로 시작하는 이름을 탐색하는 n번의 단계를 더해 다음과 같이 나타낼 수 있다.

```python
f(n) = 1 + 1 + n
```

빅 O 표기법에서는 상수 부분을 무시하고 f(n)을 지배하는 부분만 선택해 나타낸다

```python
0(n) = n
```

선형 시간 복잡도의 그래프는 아래와 같이 나타나고 데이터 세트가 커지는 만큼 알고리즘의 실행에 필요한 단계도 같은 비율로 늘어난다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fb32a252-3b2c-4cfe-89f5-ef1ccbf5e945/b41258a4-ed64-4afa-909c-c61d11fcf564/image.png)

[https://github.com/hea97/TIL/blob/main/알고리즘/알고리즘 기초/Linear Time graph.py](https://github.com/hea97/TIL/blob/main/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B8%B0%EC%B4%88/Linear%20Time%20graph.py)  
(위 링크는 선형 시간 복잡도 알고리즘 그래프 구현을 위한 python 코드이다)

# 선형 로그 시간

**선형 로그 시간(Log-Linear Time)**을 따르는 알고리즘의 복잡도는 로그 시간 복잡도와 선형 시간 복잡도를 곱한 만큼 커진다. 로그 시간으로 실행되는 알고리즘 0(log n)을 n번 반복하는 형태를 말하며, 0(n log n)으로 표기.

선형 로그 시간 알고리즘은 보통 데이터 세트를 작은 부분으로 나누고, 이들을 독립적으로 처리하는 형태를 취한다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fb32a252-3b2c-4cfe-89f5-ef1ccbf5e945/b333989d-2506-403a-8d58-c74da730c012/image.png)

[https://github.com/hea97/TIL/blob/main/알고리즘/알고리즘 기초/Log-Linear Time graph.py](https://github.com/hea97/TIL/blob/main/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B8%B0%EC%B4%88/Log-Linear%20Time%20graph.py)  
(위 링크는 선형 로그 시간 복잡도 알고리즘 그래프 구현을 위한 python 코드이다)

선형 로그 시간 복잡도는 선형 시간 복잡도보다는 비효율적이지만, 2차 시간 복잡도보다는 효율적이다.

# 2차 시간

**2차 시간 복잡도(Quadratic Time Complexity)**는 선형 로그 시간 복잡도 다음으로 효율적인 시간 복잡도. **2차 시간**으로 실행되는 알고리즘의 복잡도는 n의 제곱에 정비례하며, 0(**2)으로 표기.

2차 시간 복잡도를 따르는 알고리즘의 예제

```python
nubmers = [1, 2, 3, 4, 5]
for i in numbers:
	for j in numers:
		x = i * j
		print(x)
```

알고리즘은 숫자 리스트 `numbers`에 들어 있는 모든 숫자를 서로 곱해 변수에 저장한 후 출력.

여기서 `n`은 `numbers` 리스트의 크기, 이 알고리즘의 시간 복잡도  `f(n)`은 다음과 같이 나타낼 수 있다.

```python
f(n) = 1 + n * n * (1 + 1)
```

이 식의 (`1 + 1`) 부분은 각각 (`i * j`)를 변수 `x`에 저장하는 단계와 `print` 함수에 해당한다.  
두 번 중첩된 for 루프를 통해 곱셈과 출력을 `n * n`  번 반복한다. `f(n)`은 다음과 같이 단순화가 가능하다.

```python
f(n) = 1 + (1 + 1) * n**2
```

```python
f(n) = 1 + 2 * n**2
```

마찬가지로 f(n)의 크기를 지배하는 부분이 n**2이므로 빅 O 표기법으로

```python
0(n) = n**2
```

2차 시간 복잡도 그래프

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/fb32a252-3b2c-4cfe-89f5-ef1ccbf5e945/7dfce413-49aa-43fc-b6b0-bf9f8be0cfe4/image.png)

[https://github.com/hea97/TIL/blob/main/알고리즘/알고리즘 기초/Quadratic Time graph.py](https://github.com/hea97/TIL/blob/main/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B8%B0%EC%B4%88/Quadratic%20Time%20graph.py)  
(위 링크는 2차 시간 복잡도 알고리즘 그래프 구현을 위한 python 코드이다)

알고리즘에 1부터 n까지 또는 0부터 n-1까지 실행하는 루프가 두 번 중첩되어 있다면 그 알고리즘의 시간 복잡도는 최소한 0(n**2) 이상일 것이다. n의 제곱에 비례해 실행 시간이 늘어나는 삽입 정렬이나 버블 정렬과 같은 정렬 알고리즘의 상당수가 2차 시간 복잡도를 따른다.

# 3차 시간

**3차 시간(Cubic Time)**으로 실행되는 알고리즘의 시간 복잡도는 n의 세제곱에 정비례하며, 0(n**3)으로 표기

3차 시간 복잡도를 따르는 알고리즘의 예제

```python
nubmers = [1, 2, 3, 4, 5]
for i in numbers:
	for j in numers:
		for h in numbers:
			x = i + j + h
			print(x)
```

이 알고리즘 f(n)

```python
f(n) -= 1 + n * n * n * (1 + 1)
```

단순화

```python
f(n) = 1 + 2 * n**3
```

2차 시간 복잡도와 마찬가지로 f(n)에서 가장 중요한 부분은 n**3이다.  
n**3은 너무나 급격하게 커지기 때문에 만약 f(n)의 나머지 부분에 n**2이 포함되어 있더라도 무시할 수 있을 정도 이다. 따라서 빅 O 표기법에서는

```python
0n = n**3
```

알고리즘에 0부터 n까지 실행하는 루프가 세 번 중첩되어 있다면 그 알고리즘은 3차 시간 복잡도를 따른다. 데이터 과학이나 통계와 관련된 일을 한다면 3차 시간 복잡도 문제를 자주 마주친다.

2차와 3차 시간 복잡도는 모두 다항 시간 복잡도에 속한다.  
**다항 시간 복잡도(Polynomial time Complexity)**를 따르는 알고리즘 0(n**a)에 비례하여 커지는데, 2차 시간은 a가 2인 경우, 3차 시간은 a가 3인 경우에 해당.  
알고리즘을 설계할 때는 가급적 다항 시간 알고리즘을 피하는 편이 좋다. 이런 알고리즘은 n이 커짐에 따라 알고리즘의 실행 시간이 급격하게 늘어날 수 있기 때문이다. 하지만 가끔 피치 못하게 다항 시간 알고리즘을 사용해야 하는 경우에는 다음에 살펴볼 최악의 알고리즘과 비교했을 때 그나마 다항 시간 복잡도 괜찮은 편이라고 생각하는 것이 위안이 될 것이다.

# 지수 시간

최악의 시간 복잡도로 꼽히는 것은 **지수 시간 복잡도(Exponential Time Complexity)**.  
**지수 시간**으로 실행되는 알고리즘의 복잡도는 데잍 크기의 지수식으로 표현된다, 어떤 상수 c를 n 제곱한 만큼 실행 단계가 커지는 알고리즘으로, 빅 O 표기법에서는 0(c**n)으로 표기한다. 여기서 상수 c가 얼마나 큰지는 중요하지 않는다. 문제는 지수인 n.

다행히 지수 시간 복잡도가 자주 마주치는 문제는 아니다.  
e.g. n개의 숫자로 이루어진 비밀번호를 가능한 모든 조합을 시도해 알아내려고 하는 경우 지수 시간 복잡도에 해당하며, 0(10**n)으로 표기한다.

```python
pin = 931
n = len(pin)
for i in range(10**n):
	 if i == pin:
		 print(i)
```

알고리즘을 완료하기 위해 필요한 단계는 n이 커짐에 따라 믿을 수 없을 정도로 빠르게 커진다. n이 1이면 10번의 단계를 거쳐야 하고 n이 2이면 100번, n이 3이면, 1,000번의 단계가 필요하다. 언뜻 보기에는 지수 시간 알고리즘이 그렇게까지 빨리 커지는 것처럼 보이지않지만 감당할 수 없이 커지는 것은 순식간이다.  
여덟 자리의 비밀ㄹ번호를 알아내려면 1억번 시도해야 하고, 열 자리의 비밀번호를 알아내려면 100억 번을 시도해야 한다. 이제 비밀번호의 자릿수가 왜 그렇게 중요한지 깨달았을 것이다. 만약 네 자리의 비밀번호를 사용한다면 이런 프로그램을 토해 손쉽게 비밀번호를 알아낼 수 있다. 반면 스무 자리의 비밀 번호를 사용한다면 아마 해커가 죽을 때까지도 프로그램이 끝나지 않기 때문에 절대 알아낼 수 없을 것이다.

이런 식으로 비밀번호를 알아내는 것을 **무차별 대입 알고리즘(Brute-Force Algorithm)**이라고 한다. 무차별 대입 알고리즘은 가능한 경우의 수를 전부 대입해 보는 알고리즘.    
보통 이 알고리즘은 비효율적이므로 최후의 수단으로만 사용한다.

# 최선과 최악

알고리즘의 실행 시간, 즉 성능은 데이터의 종류를 비롯해 다양한 요인에 의해 변한다.  
따라서 알고리즘의 성능을 평가할 때는 최선과 최악, 평균의 시간 복잡도를 고려해야 한다. **최선의 경우(Best-case)**인 시간 복잡도는 알고리즘에 입력되는 데이터가 이상적일 때, **최악의 경우(Worst-case)**인 시간 복잡도는 말 그대로 가능한 모든 시나리오 중 가장 최악(알고리즘의 실행 시간이 급격하게 커지는/느려지는 경우)일 때, **평균의 경우(Average-case)**인 시간 복잡도는 알고리즘이 평균적으로 얼마나 빨리 실행되는지를 나타낸다.   

e.g. 리스트의 요소를 하나씩 탐색한다고 할 때,  
정말 운이 좋다면 탐색을 시작하자마자 첫 번째 항목에서 원하는 요소를 찾을 수도 있다. 이것이 바로 최선의 경우에 해당하는 시간 복잡도이다. 반면, 찾으려는 요소가 리스트에 없다면 리스트 전체를 탐색해야 하는 최악의 경우에 해당하는 시간 복잡도인 것이다.

리스트에 대한 순차 탐색을 100차례 수행한다고 하면 평균적으로 0(n/2)의 시간 안에 탐색이 끝날 것이다. 여기에 0(n/2)은 빅 O 표기법을 통해 0(n)으로 표기할 수 있다.   
일반적으로 알고리즘을 비교할 때는 평균의 경우인 시간 복잡도부터 살펴본다. 만약 더 깊이 분석하고 싶다면 최선과 최악의 경우인 시간 복잡도를 비교할 수 있다.

# 공간 복잡도

알고리즘의 효율을 생각할 때는 컴퓨터의 메모리도 유한한 자원이므로 시간 복잡도뿐만 아니라 자원을 얼마나 사용하는지도 고려해야 한다. **공간 복잡도(Space Complexity)**는 알고리즘의 실행을 완료할 때까지 필요한 자원의 양, 즉 고정 공가느 데이터 구조 공간, 임시 공간의 메모리를 얼마나 사용하는지 나타낸다. **고정 공간(Fixed Space)**은 프로그램 자체가 차지하는 메모리를 말하며, **자료구조 공간(Data Structure Space)**은 데이터 세트, 예를 들어 탐색의 대상이 되는 리스트를 저장하는 데 필요한 메모리를 말한다. 알고리즘에서 이 데이터를 저장하기 위해 사용하는 메모리는 n의 크기에 따라 달라진다. 또한 **임시 공간(Temporary Space)**은 알고리즘에서 중간 처리를 위해 사용하는 메모리, 예를 들어 데이터 전송을 위해 임시로 리스트 사본을 만들 때 필요한 메모리를 말한다.

앞에서 학습한 시간 복잡도의 개념을 공간 복잡도에도 적용할 수 있다.  
다음 예제로 n의 팩토리얼(factorial) (n 이하의 양의 정수를 모두 곱한 값)을 계산하는 알고리즘은 상수 공간 복잡도인 0(1)을 따른다.

```python
x = 1
n = 5
for i in range(1, n + 1):
	x = x * i
```

알고리즘의 공간 복잡도 상수인 이유는 n이 커져도 알고리즘에서 추가로 메모리를 사용하지 않기 때문이다.

반면, n까지 도달하면서 계산한 중간 결과를 모두 리스트에 저장한다면 이 알고리즘은 선형 공간 복잡도0(n)을 따른다.

```python
x = 1
n = 5
a_list = []
for i in range(1, n + 1):
	a_list.append(x)
	x = x * i
```

알고리즘에 필요한 공간 역시 n이 커지는 것과 같은 비율로 커지므로 이 알고리즘의 공간 복잡도 0(n)이 되는 것이다.

시간 복잡도와 마찬가지로 알고리즘의 공간 복잡도 역시 상황에 따라 달라지지만 일반적으로는 공간을 적게 쓸수록 좋다.

# 복잡도가 중요한 이유

컴퓨터 과학자가 알고리즘을 최적화하기 위해서는 먼저 규모에 대해 이해해야한다. 알고리즘을 개선하고 싶다면 규모를 줄일 방안을 모색해야 하는 것이다.  
e.g. for 루프가 두 번 중첩된 0(n**2)알고리즘이 있다고 했을 때, 이 알고리즘을 최적화하기 위해 루프의 내부를 검토하는 것은 생각보다 중요하지 않다. 중첩된 for 루프를 사용하지 않을 수 있는지, 다시 말해 알고리즘의 규모를 줄일 수 있는지 판단하는 것이 훨씬 더 중요하다

같은 문제를 중첩되지 않은 두 개의 for 루프를 쓰는 알고리즘으로 풀 수 있다면 이 알고리즘의 시간 복잡도는 0(n)이 되고, 두 경우의 성능은 크게 차이 나게 된다. 0(n**2)인 알고리즘을 조정하여 아무리 효율을 올린다고 해도 0(n)으로 고쳐 쓰는 것에는 비교할 수 없다. 하지만 알고리즘의 최선 또는 최악의 경우에는 0(n)과 같은 결과를 낼 수 있고, 최선의 경우에 해당하는 데이터일 수 있다. 만약 이런 경우라면 0(n**2)인 알고리즘도 좋은 선택이다

알고리즘을 잘 선택하는 것은 실제로 큰 영향을 미친다.  
e.g. 웹 개발자이고, 사용자의 요청에 따라 알고리즘을 작성할 책임이 있다고 했을 때, 상수 시간 알고리즘을 선택하는지, 2차 시간 알고리즘을 선택하는지에 따라 스스로에 대한 평가가 엇갈릴 수 있다.  
상수 시간 알고리즘을 선택해 1초 안에 고객의 요청을 처리할 수 있다면 고객은 다시 찾아오게 될 것이고, 반대로 2차 시간 알고리즘을 선택해 고객의 요청을 1분 이상 지연시켰다면 그 고객은 두 번 다시 방문하지 않을 것이다.