데이터 엔지니어링은 기업 데이터를 활용하는 작업을 시작한 후 어떤 형태로든 존재해 왔음, 2019년대 데이터 과학의 부상과 함께 주목받기 시작.

**데이터 엔지니어링(Data Engineering)**과 **데이터 엔지니어(Data Engineer). 정의**.

**데이터 엔지니어링**은 데이터 과학, 데이터 분석가, 비즈니스 인텔리전스 개발자, 그리고 조직 내의 다른 전문가가 데이터를 사용하 수 있또록 만드는 일련의 작업. 대규모의 데이터를 수집 및 저장하면서 추가 분석을 수행할 수 있는 데이터를 준비하기 위한 시스템을 설계하고 구축하려면 데이터 엔지니어와 같은 전담 전문가가 필요하다. 간단히, 데이터 엔지니어는 조직의 데이터 인프라를 구축하고 운영해 데이터 분석가와 데이터 과학자가 추가 분석을 수행을 할수 있도록 준비.

**데이터 엔지니어링**은  

1. **SQL 중심**.   
데이터의 작업 및 기본 저장소는 관계형 데이터베이스. 모든 데이터 처리는 SQL 또는 SQL 기반 언어로 수행. 때때로 이러한 데이터 처리는 ETL 도구를 사용해 수행.
2. **빅데이터 중심**.  
데이터 작업 및 기본 스토리지는 하둡(hadoop), 카산드라(Cassanda), HBase, 플랑크(Flink)와 같은 빅데이터 프레임워크에서 수행. SQL이 사용되는 동안 기본 처리는 자바, 스칼라, 파이썬과 같은 프로그래밍 언어.

기존 역할과 관련해 데이터 엔지니어링 분야는 SW 엔지니어링에서 더 많은 요소를 가져오는 비즈니스 인텔리전스와 데이터 웨어하우징의 상위집합(superset). 이 분야는 확장된 하둡 생태계, 스트림 처리, 규모에 다른 컴퓨팅에 대한 개념과 함께 ‘빅데이터’ 분산 시스템의 운영에 관한 전문화를 통합.

데이터 엔지니어링은 데이터의 이동, 조작, 관리에 관한 모든 것.

# 데이터 엔지니어링 정의

다양한 사람이 데이터 엔지니어링을 어떻게 정의하는가에 관한 공통된 맥락을 풀어보면 ‘데이터 엔지니어가 데이터를 가져와 저장, 데이터 과학자, 분석가 등이 사용할 수 있도록 준비’ 패턴.

> 데이터 엔지니어링은 원시 데이터(raw data)를 가져와 분석 및 머신러닝과 같은 다운스트림 사용 사례를 지원하는, 고품질의 일관된 정보를 생성하는 시스템과 프로셋스의 개발, 구현 및 유지 관리. 데이터 엔지니어링은 보안, 데이터 관리, 데이터 운영, 데이터 아키텍처, 오케스트레이션, SW 엔지니어링의 교차점.
> 

데이터 엔지니어는 원천 시스템에서 데이터를 가져오는 것부터 시작 분석 또는 머신러닝 같은 사용 사례에 데이터를 제공하는 것으로 끝나는 데이터 엔지니어링 수명 주기를 관리.

# 데이터 엔지니어링 수명 주기

근시안적으로 기술 집착하면 더 큰 그림을 놓치기 쉽다.  
**데이터 엔지니어링 수명 주기(data engineering lifecycle)**라는 거대한 아이디어 중심.  
이를 통해 데이터 엔지니어들이 자신의 역할 파악할 수 있는 전체적인 맥락을 제공한다고 가정.

---

**데이터 엔지니어링 수명 주기**

생성 → 저장(수집 → 변환 → 서빙) → 분석, ML, 역 ETL

---

**드러나지 않는 요소**

보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어엔지니어링

---

데이터 엔지니어링 수명 주기는 기술에서 벗어나, 데이터 자체와 데이터가 제공해야 하는 최종 목표관한 논의로 전환. 데이터 엔지니어링 수명 주기의 단계.

- **데이터 생성(generation)**
- **데이터 저장(storage)**
- **데이터 수집(ingestion)**
- **데이터 변환(transformation)**
- **데이터 서빙(serving)**

데이터 엔지니어링 수명 주기는 전체 수명 주기에 걸쳐 중요한 아이디어인 **드러나지 않은 요소(underecurrent)** 개념 포함. 여기에는 보안, 데이터 관리, 데이터 옵스, 데이터 아키텍처, 오케스트레이션, 소프트웨어 엔지니어링 포함.

# 데이터 엔지니어의 진화

> 역사는 그대로 반복되지 않지만, 그 흐름은 분명 반복된다.
> 

현재와 미래의 데이터 엔지니어링을 이해하려면 해당 분야가 어떻게 발전했는지에 관한 맥락 파악.  
역사를 다루는 부분은 아니지만, 과거를 돌아보는 작업은 오늘날 우리가 어디에 있고 상황이 어디로 흘러가는지를 이해하는 데 매우 주용. 

## 1980년부터 2000년까지 : 데이터 웨어하우징에서 웹으로

데이터 엔지니어 탄생은 1970년대까지 거슬러 올라가는 데이터 웨어하우징에 뿌리를 둔다.  
**비즈니스 데이터 웨어하우스(business data warehouse)**라는 용어 1980년대 형성, 1989년에 이르러 빌 인먼(Bill Inmon)이 **데이터 웨어하우스**라는 용어를 공식적으로 만들었다.  
IBM의 엔지니어들이 관계형 데이터베이스와 구조적 질의 언어(SQL, Structured Query Language) 개발한 이후 오라클은 이 기술을 대중화. 초기 데이터 시스템의 성장에 따라 기업은 보고와 비즈니스 인텔리전스(BI)를 위한 전용 툴과 데이터 파이프라인이 필요. 랄프 킴벌(Ralph Kimball)과 빌 인먼은 사람들이 데이터 웨어하우스에서 비즈니스 로직(business logic)을 올바르게 모델링할 수 있도록 돕고자, 오늘날에도 널리 쓰이는 (각자의 이름을 딴) 데이터 모델링 기법과 접근 방식을 개발.

데이터 웨어하우징은 시장에 출시되는 대량의 데이터를 처리, 전례 없는 막대한 양의 데이터를 지원, 다수의 프로세서를 사용하는 새로운 대규모 병렬 처리(MPP) 데이터베이스로 확장성 있는 분석의 첫 시대를 열었다. BI 엔지니어, ETL 개발자, 데이터 웨어하우스 엔지니어와 같은 역할 데이터 웨어하우스의 다양한 요구 사항을 해결. 데이터 웨어하우스와 BI 엔지니어링은 오늘날의 데이터 엔지니어링의 선구자였으며 여전히 이 분야에서 중심적인 역할.

인터넷은 1990년대 중반에 주류를 이루었고 AOL, 야후(Yaoo), 아마존(Amaozn)과 같은 새로운 세대의 웹 우선(web-first) 기업을 탄생. 닷컴 열풍은 웹 애플리케이션과 이를 지원하는 백엔드 시스템(서버, 데이터베이스, 스토리지)에서 엄청난 활동을 만들어냈다. 대부분 인프라는 비용이 많이 들고, 거대 했으며, 라이선스의 부담이 매우 컸다. 이러한 bakc 시스템 밴더들은 웹 애플리케이션이 생성할 데이터의 어마어마한 규모를 예상하지 못했을 것이다.

## 2000년대 초 : 현대 데이터 엔지니어링의 탄생

90년대 후반 닷컴 열풍이 문저지고 작은 무리의 생존자들만이 남겨진다. 일부인 야후, 구글, 아마존과 같은 기업들은 강력한 기술 기업으로 성장. 처음에는 이들 1990년대 전통적인 모놀리식 관계형 데이터 베이스와 데이터 웨어하우스에 계속 의존하면서 그러한 시스템을 한계까지 몰아붙였다.   
하지만 해당 시스템이 불안정해짐에 따라 데이터 증가를 처리할 최신화된 접근 방식이 필요. 차세대 시스템은 비용 효율적이고, 화장성과 가용성이 있으며, 안정적이어야 한다.

데이터의 폭발적 증가와 함께 서버, RAM, 디스크, 플래시 디라이브와 같은 범용 HW도 저렴해지고 어디서나 사용할 수 있게 되었다. 몇 가지 혁신은 대규모 컴퓨팅 클러스터에서의 분산 연산 및 저장을 실현. 이러한 혁신은 전통적인 모놀리식 서비스를 분산하고 분리하기 시작.  
이른바 ‘빅데이터’ 시대가 시작

오스퍼드 영어 사전은 빅데이터를 ‘특히 인간의 행동 및 상호 작용과 관련한 패턴, 경향, 연관성을 밝히고자 계산적으로 분석될 수 있는 큰 데이터셋’이라 정의. 빅데이터에 대한 또 다른 유명하고 간결한 설명은   
데이터의 **3V, 즉 속도(veloviy), 다양성(variety), 크기(volkume)**

2003년 구글은 구글 파일 시스템(Google File System)에 관한 논문 발표, 그 직후 2004년에는 초확장 데이터 처리 패러다임인 맵리듀스에 대한 논문 발표.  
사실 빅데이터는 실험 물리학 프로젝트를 위한 MPP 데이터 웨어하우스와 데이터 관리 분야에서 이미 선례가 있었지만, 구글의 논문은 오늘날 우리가 아는 데이터 기술과 데이터 엔지니어링의 문화적 근간을 위한 ’빅뱅’을 일으켰다.

구글 논문들은 야후의 엔지니어들이 2006년에 아파치 하둡을 개발 나중에 오픈 소스화하는 데 영감을 주었다. 이때 개발된 하둡의 영향력은 데이터 엔지니어링 전체에 영향을 미쳤다. 대규모 데이터 문제에 관심이 있는 소프트웨어 엔지니어들은 새로운 오픈 소스 기술 생태계의 가능성에 주목. 모든 규모와 유형의 기업들이 다루는 데이터가 테라바이트, 심지어 패타바이트 규모로 증가 빅데이터 엔지니어의 시대 탄생

비슷한 시기 아마존은 폭발적으로 증가하는 데이터 요구에 대응.  
아마존 탄력적인 컴퓨팅 환경인 EC2(Amaozn Elastic Compute Cloud)무한 확장이 가능한 스토리지 시스템인 S3(Amazon Simle Storage Service), 확장성이 뛰어난 NoSQL 데이터베이스인 다이나모DB를 비롯한 많은 핵심 데이터 빌딩 블록을 구축. 아마존은 **아마존 웹 서비스(AWS, Amazon Web Services)**를 통해 이러한 서비스들은 내외부 소비요으로 제공, 가장 인기 있는 퍼블릭 클라우드 서비스가 됐다. AWS는 방대한 범용 HW 풀을 가상화하고 재판매해 매우 유연한 종량제 자원 시장을 만들어냈다. 데이터 센터용 HW 구입하는 대신 개발자 AWS에서 컴퓨팅과 스토리지 자원을 대여

AWS 아마존의 높은 수익성을 책임지는 성장 엔진 되면서 구글 클라우드(Google Cloud), 마이크로소프트 애저(Microsoft Azure), 디지털오션(Digital Ocean)과 같은 다른 퍼플릭 클라우드가 잇따라 등장.  
퍼블릭 클라우드가 21헤기의 매우 중요한 혁신인 것은 부인할 수 없는 사실, SW와 데이터 애플리케이션의 개발 및 배포 방식에 혁명.

초기 빅데이터 도구 퍼블릭 클라우드는 오늘날 데이터 생태계 토대 말현.  
현대 데이터 환경과 우리가 지금 아는 데이터 에진니어링은 이러한 혁신 없었다면 존재X

## 2000년대와 2010년대 빅데이터 엔지니어링

하둡 생태계의 오픈 소스 빅데이터 도구는 빠르게 성숙, 실리콘밸리에서 전 세계의 최신 기술에 정통한 기업들로 빠르게 환산. 모든 기업이 처음으로 최고 수준의 기술 업체에서 사용하는 것과 동일한 최첨단 데이터에 접근. 배치 컴퓨팅에서 이벤트 스트리밍으로의 전환과 함께 또 다른 혁명이 발생 ‘실시간 빅데이터’의 새로운 시대를 열었음.

엔지니어는 하둡, 피그(Apache pig), 하이브(Apache Hive), 드레멜(Dremel), HBase(Apache HBase), 스톰(Apache Storm), 카산드라, 스파크, 프레스토(Presto) 및 실제 업무 현장에 등장한 수많은 기타 신기술 중 가장 뛰어난 최신 기술을 서택, 기존의 엔터프라이즈 지향적이고 GUI 기반인 데이터 도구는 갑자기 구식으로 느껴졌고, 맵리듀스의 출현으로 코드 우선(code-first) 엔지니어링이 유행.

2000년대 후반 2010년대 데이터 도구가 폭발적으로 증가 **빅데이터 엔지니어(big dataengineer)**가 탄생.  
하둡, 안(YARN), HDFS(Hadoop Distributed File System), 맵리듀스를 포함 하둡 생태계 같은 도구 기술을 효과적으로 사용하려면 빅데이터 엔지니어가 SW 개발 및 저수준의 인프라 해킹에 능숙해야 했지만, 가옺점이 바뀌게 됐다. 빅데이터 엔지니어는 보통 대규모데이터를 제공하고자 사용 HW의 대규모 클러스터를 유지 관리. 때떄로 하둡 핵심 코드에 풀 리퀘스트(pull request)를 보낼 수도 있었지만, 그들은 해심 기술 개발에서 데이터 전달 초점을 옮겼다.

빅데이터는 순신간에 성공의 희생양이 됐다.  
**빅데이터**는 2000년대 초반부터 2010년대 중반까지 인기 있는 유형어. 빅데이터는 점점 증가하는 데이터양과 빅데이터 도구 및 서비스를 판매하는 기업들이 펼치는 파렴치한 마케팅의 끊없는 공세 속에서 이를 이해하려는 기업들의  상상력을 사로 잡았다. 엄청난  과대광고의 영향으로 기업들이 작은 데이터 문제에도 빅데이터를 사용하는 경우도 있었다. 모두 빅데이터 작업에 참여하기를 원하는 듯 보였다.   
댄 아리엘리(Dan Arlely)는 트위터에서 모두가 그것에 관해 이야기하지만, 실제로 하는지 아는 사람은 아무도 없다. 하지만 다른 모든 사람이 그것을 하고 있다고 생각하기 떄문에, 자신도 그것을 한다고 주장!

빅데이터의 흥망성쇠를 파악하는 검색어 ‘big data’의 구글 트렌드 스냅숏을 보여준다,  
하지만 용어 자체의 인기에도 불구하고 막상 빅데이터는 점차 활력을 잃게 됐다.

한마디로 말하자면 **단순화(simplification)**.  
오픈 소스 빅데이터 도구는 강력함녀서도 정교했지만, 이를 관리하려면 많은 작업과 지속적인 관심이 필요. 몇몇 회사는 이러한 플랫폼을 관리하고자 연간 수백만 달러의 비용을 들여 빅데이터 엔지니어들을 팀 단위로 고용. 빅데이터 엔지니어는 복잡한 도구를 유지 관리하는 데 관도한 시간을 할애, 비즈니스의 통찰력과 가치를 제공하는 데는 많은 시간을 소비하지 않는 경우가 많다

오픈 소스 개발자와 클라우드 업체, 서드파티 업체들은 높은 관리 오버헤드와 클러스터 관리 비용 그리고 오픈 소스 코드의 설치, 구성, 업그레이드 없이 빅데이터를 추상호하고 단순화하며 사용 가능하게 만드는 방법 찾기 시작. **빅데이터**라는 용어는 본질적으로 많은 양의 데이터를 처리하는 특정 시간과 접근 방식을 설명하는 유물.

오늘날 데이터는 그 어느 때보다 빠르게 이동하고 점점 더 커지고 있지만, 빅데이터 처리는 더이상 별도의 용어를 사용할 가치가 없을 만큼 접근성이 좋아졌다. 모든 회사는 실제 데이터 크기와 관계없이 데이터 문제를 해결하는 것을 목표로 한다. 이제 빅데이터 에니진어는 그저 **데이터 엔지니어**.

## 2020년대: 데이터 수명 주기를 위한 엔지니어링

데이터 엔지니어링의 역할은 빠르게 진화하고 있다.  
이러한 진화가 앞으로도 빠른 속도로 지속되기를 기대하며 데이터 엔지니어는 역사적으로 하둡, 스파크 또는 인포메티카(Informatica)와 같은 모놀리식 프레임워크의 저수준의 세부 정보를 사용하는 경향이 있었다.  
하지만 이제는 그 트랜드가 분산, 모듈화, 관리, 고도로 추상화된 도구로 이동 중이다.

실제로 데이터 도구는 놀라운 속도로 화산했다.  
2020년대 초반 인기있는 트랜드는 분석가의 삶을 더 쉽게 만들고자 조립된 사용 오픈 소스와 서드파티 제품들의 모음을 나타내는 **모덴 데이터 스택(moden data stack)**을 포함.     
동시에 데이터 원천(data source)과 데이터 형식은 그 다양성과 크기가 계속 증가. 데이터 엔지니어링은 점차 궁극적인 비즈니스 목표를 달성하고자 다양한 기술 마치 레고 블록처럼 연결하고 상호 운용(Interoperability) 분야.

**데이터 수명 주기 엔지니어(data lifecycle engineer)**는 더 강화된 추상화와 단순화 덕분에 더는 과거 빅데이터 프레임워크의 끔찍한 세부 사항의 방해 받지 않는다. 데이터 엔지니어는 여전히 저수준의 데이터 프로그래밍 기술을 유지하고 필요에 따라 이를 사용. 하지만 보안, 데이터 관리, 데이터옵스, 데이터 아키텍처, 오케스트레이션 및 일반 데이터 수명 주기 관리와 같은 가치 사슬의 상위 영역에 자신의 역할이 점점 더 집중되고 있음을 발견.

도구와 워크플로가 단순해짐에 따라 데이터 엔지니어의 태도에도 눈에 띄는 변화 나타남.  
누가 ‘가장 큰 데이터’를 보유하는지에 초점을 맞추는 대신, 오픈 소스 프로젝트와 서비스는 데이터 관리와 통계, 사용 및 발견의 용이성, 그리고 품질 향상에 점점 더 많은 과심을 기울이고 있다. 데이터 엔지니어는 이제 **CCPA와 GDPR** 같은 약어에 정통.  
파이프라인을 설계할 때는 개인정보보호, 익명화, 데이터 가비지 수집 및 규정 준수에 관심을 가지고 고민.

오래된 것이 다시 새로운 것이 된다. (데이터 품질과 거버넌스를 포함) 데이터 관리와 같은 ‘기업화(enterprisey)’ 사항들은 빅데이터 이전 시대의 대기업에서는 일반적, 소규모 기업에서는 널리 채택되지 않았다. 과거 데이터 시스템의 많은 도전적인 문제가 해결, 깔끔하게 제품화, 패키지화되면서 기술자와 기업가는 ‘기업화’ 사항들로 다시 초점을 옮겼지만, 전통적인 기업의 지휘 통제 접근 방식과는 대조적으로 탈중앙화(decentralization)와 민첩성(agility)에 중점.

현재 데이터 수명 주기 관리의 황금기.  
데이터 엔지니어링 수명 주기를 관리하는 데이터 엔지니어는 그 어느 때보다 더 나은 도구와 기술을 보유.

# 데이터 엔지니어링과 데이터 과학

데이터 엔지니어링과 데이터 과학의 연관성.  
데이터 엔지니어링이 데이터 과학의 하위 분야라는 주장과 함께 일부 논쟁이 벌어지고 있다. 데이터 엔지니어링이 데이터 과학 및 분석과 **별개(separate)**라고 가정. 서로를 보완, 분명히 다른 개념이다.  
데이터 엔지니어링은 데이터 과학의 업스트림에 위치. 데이터 엔지니어는 데이터 과학자가 사용할 입력값을 제공, 데이터 과학자는 이렇게 입력된 값들을 유용한 결과로 변환한다는 의미.

| 데이터 엔지니어링 | → | 데이터 과학과 분석 |
| --- | --- | --- |
| 업스트림 |  | 다운스트림 |

데이터 과학 욕구 단계 2017년 모니카 로가티(Monica Rogati)는 기사를 통해 피라미드 계층 구조를 발표했다. 이 계층 구조는 AI와 ML이 데이터 이동 및 저장, 수집, 인프라와 같은 더 ‘평이한’ 영역에 근접했음을 보여준다. (표로 표현)

|  | AI, DL |
| --- | --- |
| 학습/최적화 | A/B 테스트, 실험, 단순 ML 알고리즘 |
| 집계/라벨링 | 분석, 측정 지표, 세그먼트, 집계, 특성, 훈련 데이터 |
| 탐색/변환 | 정제, 이상 감지, 준비 |
| 이동/저장 | 신뢰할 수 있는 데이터 흐름, 인프라, 파이프라인, ETL, 정형/비정형 데이터 저장 |
| 수집 | 계측, 로깅, 센서, 외부 데이터, 사용자 생성 콘텐츠 |

많은 데이터 과학자가 ML 모델을 구축 튜닝하기 원하지만, 실제 작업 시간 70 ~ 80%는 계층 구조상 하위 세부분 (데이터 수집, 정리, 처리)에 시간을 소비하는 것으로 추정, 분석과 ML에 할애하는 시간은 극히 일부 불과. 로가티는 기업이 AI나 ML과 같은 영역을 다루기 전에 견고한 데이터 기반(계층 구조의 하위 3개 수준)을 구축.

데이터 과학자는 보통 사용 제품 수준의 데이터 시스템을 엔지니어링하도록 훈련받지 않았음, 데이터 엔지니어의 기술적 지원과 리소스(resource)의 부족 때문에 이러한 작업을 닥치는 대로 수행.  
이상적인 환경에서 데이터 과학자는 분석, 실험 및 ML과 같은 피라미드의 최상위 계층에 90% 이상의 시간을 집중. 데이터 엔지니어가 계층 구조의 최하단에 있는 작업에 집중, 데이터 과학자가 성공할 수 있는 견고한 기반을 구축

데이터 확학이 고급 분석과 ML을 주도하는 가운데, 데이터 엔지니어링은 데이터를 얻는 것과 데이터에서 가치를 얻는 것 사이의 경계를 넘나든다. 데이터 엔지니어링이 데이터 과학과 똑같이 중요하고 가기성을 지니며, 데이터 엔지니어가 데이터 과학을 실제 현장에서 성공하도록 만드는 데 중요한 역할 수행.

| 다양한 원천 시스템으로부터의 데이터 | → | 데이터 엔지니어링 | → | 데이터 과학과 분석 |
| --- | --- | --- | --- | --- |